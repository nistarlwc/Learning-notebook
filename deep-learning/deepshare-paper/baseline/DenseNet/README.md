# DenseNet  

## *研究背景*  
**Short Paths**  
![](屏幕快照2020-10-28下午2.44.01.png)
![](屏幕快照2020-10-28下午2.45.29.png)

**多级特征复用 Feature Reuse**  
！ 无需额外运算  
![](屏幕快照2020-10-28下午2.46.28.png)
![](屏幕快照2020-10-28下午2.50.56.png)

**网络**
![](屏幕快照2020-10-28下午3.12.33.png)  
![](屏幕快照2020-10-28下午3.23.09.png)  
![](无标题1.png)  
![](无标题2.png)  
![](无标题3.png)  
每个层仅有k个特征是自己独有的

![](无标题4.png)  
Bottleneck
 layer作用是降低特征数量，从而提升计算效率 

![](无标题5.png)  
![](无标题6.png)  
![](无标题7.png)  


综合来看，DenseNet的优势主要体现在以下几个方面：  
1. 由于密集连接方式，DenseNet提升了梯度的反向传播，使得网络更容易训练。由于每层可以直达最后的误差信号，实现了隐式的“deep supervision”；  
2. 参数更小且计算更高效，这有点违反直觉，由于DenseNet是通过concat特征来实现短路连接，实现了特征重用，并且采用较小的growth rate，每个层所独有的特征图是比较小的；  
3. 由于特征复用，最后的分类器使用了低级特征。
4. 减轻了vanishing-gradient（梯度消失）